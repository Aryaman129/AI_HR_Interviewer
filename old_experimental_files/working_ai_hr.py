"""
üöÄ WORKING AI HR SYSTEM - FULLY FUNCTIONAL
Fixed Ollama integration, working interviews, and real AI responses
"""

import streamlit as st
import json
import time
import uuid
import requests
from datetime import datetime
import numpy as np

# Page configuration
st.set_page_config(
    page_title="üöÄ Working AI HR System",
    page_icon="üöÄ",
    layout="wide"
)

# Enhanced CSS with perfect contrast
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    .main {
        font-family: 'Inter', sans-serif;
        color: #000000 !important;
    }

    .main * {
        color: #000000 !important;
    }

    .working-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #ffffff !important;
        padding: 3rem 2rem;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
    }

    .working-header * {
        color: #ffffff !important;
    }

    .working-header h1 {
        font-size: 3.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
        color: #ffffff !important;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
    }

    .status-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        border: 1px solid #e9ecef;
        margin: 1rem 0;
        color: #000000 !important;
    }

    .status-card * {
        color: #000000 !important;
    }

    .status-online {
        border-left: 4px solid #28a745;
        background: linear-gradient(135deg, #d4edda, #c3e6cb);
    }

    .status-offline {
        border-left: 4px solid #dc3545;
        background: linear-gradient(135deg, #f8d7da, #f5c6cb);
    }

    .conversation-bubble {
        padding: 1.5rem;
        margin: 1rem 0;
        border-radius: 20px;
        max-width: 85%;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        color: #000000 !important;
    }

    .conversation-bubble * {
        color: #000000 !important;
    }

    .ai-bubble {
        background: linear-gradient(135deg, #e3f2fd, #bbdefb);
        margin-left: auto;
        border-bottom-right-radius: 8px;
        border-left: 4px solid #2196f3;
    }

    .user-bubble {
        background: linear-gradient(135deg, #f3e5f5, #e1bee7);
        margin-right: auto;
        border-bottom-left-radius: 8px;
        border-right: 4px solid #9c27b0;
    }

    .candidate-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9ff 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1.5rem 0;
        border: 1px solid #e1e5e9;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
        transition: all 0.3s ease;
        color: #000000 !important;
    }

    .candidate-card * {
        color: #000000 !important;
    }

    .candidate-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 15px 35px rgba(0, 0, 0, 0.15);
    }

    .stButton > button {
        border-radius: 10px;
        border: none;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        color: #000000 !important;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
    }
</style>
""", unsafe_allow_html=True)

# AI Integration Class
class WorkingAIEngine:
    """Working AI engine with real Ollama integration"""

    def __init__(self):
        self.ollama_url = "http://localhost:11434"
        self.model_name = "qwen2:latest"  # Using available model
        self.conversation_history = []

    def check_ollama_connection(self):
        """Check if Ollama is running and accessible"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                available_models = [model['name'] for model in models]
                return True, available_models
            return False, []
        except Exception as e:
            return False, str(e)

    def generate_ai_response(self, user_message, candidate_info=None, job_requirements=None):
        """Generate real AI response using Ollama"""
        try:
            # Build context-aware prompt
            context = self._build_interview_context(candidate_info, job_requirements)

            prompt = f"""You are an experienced HR interviewer conducting a professional job interview.

{context}

Conversation so far:
{self._format_conversation_history()}

Candidate just said: "{user_message}"

Provide a professional, engaging follow-up question or response. Keep it conversational and relevant to their background. Limit to 1-2 sentences for voice interviews.

Your response:"""

            # Make request to Ollama
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 100,
                        "top_p": 0.9
                    }
                },
                timeout=30
            )

            if response.status_code == 200:
                ai_response = response.json()['response'].strip()

                # Clean up response
                if ai_response.startswith('"') and ai_response.endswith('"'):
                    ai_response = ai_response[1:-1]

                return ai_response
            else:
                return "I understand. Could you tell me more about that experience?"

        except Exception as e:
            st.error(f"AI Error: {e}")
            return "That's interesting. What else would you like to share about your background?"

    def _build_interview_context(self, candidate_info, job_requirements):
        """Build context for AI interview"""
        context = ""

        if candidate_info:
            context += f"Candidate: {candidate_info.get('name', 'Unknown')}\n"
            context += f"Experience: {candidate_info.get('experience_years', 0)} years\n"
            context += f"Skills: {', '.join(candidate_info.get('skills', []))}\n"

        if job_requirements:
            context += f"Role: {job_requirements.get('role', 'Position')}\n"
            context += f"Required Skills: {', '.join(job_requirements.get('required_skills', []))}\n"

        return context

    def _format_conversation_history(self):
        """Format conversation history for context"""
        if not self.conversation_history:
            return "This is the start of the interview."

        formatted = ""
        for entry in self.conversation_history[-3:]:  # Last 3 exchanges
            role = "Interviewer" if entry['role'] == 'ai' else "Candidate"
            formatted += f"{role}: {entry['message']}\n"

        return formatted

    def start_interview(self, candidate_info, job_requirements):
        """Start interview with AI-generated opening"""
        self.conversation_history = []

        opening_prompt = f"""Generate a professional, welcoming opening statement for a job interview.

Candidate: {candidate_info.get('name', 'the candidate')}
Role: {job_requirements.get('role', 'this position')}
Experience: {candidate_info.get('experience_years', 0)} years

Create a warm, professional greeting that mentions their background and asks an engaging opening question. Keep it to 2-3 sentences.

Opening:"""

        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": opening_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 80
                    }
                },
                timeout=20
            )

            if response.status_code == 200:
                opening = response.json()['response'].strip()
                if opening.startswith('"') and opening.endswith('"'):
                    opening = opening[1:-1]
            else:
                opening = f"Hello {candidate_info.get('name', '')}! Welcome to the interview for the {job_requirements.get('role', 'position')} role. I'm excited to learn more about your {candidate_info.get('experience_years', 0)} years of experience. What initially drew you to this opportunity?"

        except Exception as e:
            opening = f"Hello {candidate_info.get('name', '')}! Welcome to the interview. I'd love to start by hearing what interests you most about this role."

        self.conversation_history.append({
            'role': 'ai',
            'message': opening,
            'timestamp': datetime.now().isoformat()
        })

        return opening

# Initialize session state
def init_working_session_state():
    """Initialize working session state"""
    if 'ai_engine' not in st.session_state:
        st.session_state.ai_engine = WorkingAIEngine()

    if 'candidates' not in st.session_state:
        st.session_state.candidates = []

    if 'job_requirements' not in st.session_state:
        st.session_state.job_requirements = {}

    if 'interview_active' not in st.session_state:
        st.session_state.interview_active = False

    if 'selected_candidate' not in st.session_state:
        st.session_state.selected_candidate = None

    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []

def load_working_demo_data():
    """Load working demo data"""
    st.session_state.candidates = [
        {
            "id": str(uuid.uuid4()),
            "name": "Alex Chen",
            "email": "alex.chen@email.com",
            "phone": "+1-555-0101",
            "match_score": 94.2,
            "skills": ["Python", "Machine Learning", "TensorFlow", "AWS", "Docker"],
            "experience_years": 7,
            "status": "Pending",
            "education": ["PhD in Computer Science", "Google Cloud Certified"],
            "previous_companies": ["Google", "Microsoft", "OpenAI"],
            "salary_expectation": "$150,000 - $180,000",
            "location": "Remote"
        },
        {
            "id": str(uuid.uuid4()),
            "name": "Sarah Williams",
            "email": "sarah.williams@email.com",
            "phone": "+1-555-0102",
            "match_score": 87.6,
            "skills": ["JavaScript", "React", "Node.js", "GraphQL", "MongoDB"],
            "experience_years": 5,
            "status": "Pending",
            "education": ["Bachelor of Science in Software Engineering"],
            "previous_companies": ["Netflix", "Spotify", "Airbnb"],
            "salary_expectation": "$110,000 - $130,000",
            "location": "Hybrid"
        }
    ]

    st.session_state.job_requirements = {
        'role': 'Senior Full-Stack Engineer',
        'department': 'Engineering',
        'required_skills': ['Python', 'JavaScript', 'React', 'AWS'],
        'min_experience': 5,
        'salary_range': '$120,000 - $160,000'
    }

    st.success("‚úÖ Working demo data loaded!")

def main():
    """Main working application"""
    init_working_session_state()

    # Header
    st.markdown("""
    <div class="working-header">
        <h1>üöÄ Working AI HR System</h1>
        <p>Fully Functional with Real AI Integration</p>
    </div>
    """, unsafe_allow_html=True)

    # Check AI connection status
    is_connected, models_or_error = st.session_state.ai_engine.check_ollama_connection()

    # Status display
    if is_connected:
        st.markdown(f"""
        <div class="status-card status-online">
            <h3>‚úÖ AI System Online</h3>
            <p>Connected to Ollama ‚Ä¢ Models Available: {len(models_or_error)}</p>
            <p>Ready for intelligent interviews with real AI responses</p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="status-card status-offline">
            <h3>‚ùå AI System Offline</h3>
            <p>Cannot connect to Ollama: {models_or_error}</p>
            <p>Please ensure Ollama is running: <code>ollama serve</code></p>
        </div>
        """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.title("üéõÔ∏è Working AI HR")

        page = st.selectbox(
            "Choose Module:",
            ["üè† Dashboard", "üé§ AI Interview", "‚öôÔ∏è Settings"]
        )

        st.markdown("---")

        if st.button("üìÅ Load Demo Data"):
            load_working_demo_data()

        if st.button("üîÑ Test AI Connection"):
            is_connected, result = st.session_state.ai_engine.check_ollama_connection()
            if is_connected:
                st.success(f"‚úÖ Connected! {len(result)} models available")
            else:
                st.error(f"‚ùå Connection failed: {result}")

    # Route to pages
    if page == "üè† Dashboard":
        show_working_dashboard()
    elif page == "üé§ AI Interview":
        show_working_interview()
    elif page == "‚öôÔ∏è Settings":
        show_working_settings()

def show_working_dashboard():
    """Working dashboard with functional buttons"""
    st.header("üè† AI-Powered Dashboard")

    # Metrics
    if st.session_state.candidates:
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Total Candidates", len(st.session_state.candidates))

        with col2:
            high_score = len([c for c in st.session_state.candidates if c.get('match_score', 0) >= 85])
            st.metric("High Performers", high_score)

        with col3:
            avg_score = sum(c.get('match_score', 0) for c in st.session_state.candidates) / len(st.session_state.candidates)
            st.metric("Average Score", f"{avg_score:.1f}%")

        with col4:
            pending = len([c for c in st.session_state.candidates if c.get('status') == 'Pending'])
            st.metric("Pending Interviews", pending)

    # Candidates with working buttons
    st.subheader("üéØ Candidates - Click to Start AI Interview")

    if st.session_state.candidates:
        for candidate in st.session_state.candidates:
            st.markdown(f"""
            <div class="candidate-card">
                <h4>üë§ {candidate['name']}</h4>
                <div style="display: flex; justify-content: space-between; margin-bottom: 1rem;">
                    <div>
                        <strong>Match Score:</strong> <span style="color: {'#28a745' if candidate['match_score'] >= 85 else '#ffc107' if candidate['match_score'] >= 70 else '#dc3545'}; font-weight: bold;">{candidate['match_score']:.1f}%</span><br>
                        <strong>Experience:</strong> {candidate['experience_years']} years<br>
                        <strong>Status:</strong> {candidate['status']}
                    </div>
                    <div>
                        <strong>Email:</strong> {candidate['email']}<br>
                        <strong>Location:</strong> {candidate.get('location', 'Not specified')}<br>
                        <strong>Salary:</strong> {candidate.get('salary_expectation', 'Not specified')}
                    </div>
                </div>
                <div>
                    <strong>Skills:</strong> {', '.join(candidate['skills'])}
                </div>
            </div>
            """, unsafe_allow_html=True)

            # Working action buttons
            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button(f"üé§ Start AI Interview", key=f"interview_{candidate['id']}", type="primary"):
                    start_working_interview(candidate)

            with col2:
                if st.button(f"üëÅÔ∏è View Profile", key=f"view_{candidate['id']}"):
                    show_candidate_profile(candidate)

            with col3:
                if st.button(f"üìß Send Email", key=f"email_{candidate['id']}"):
                    st.success(f"üìß Interview invitation sent to {candidate['name']}")
    else:
        st.info("No candidates available. Click 'Load Demo Data' in the sidebar to get started.")

def start_working_interview(candidate):
    """Start a working AI interview"""
    if not st.session_state.ai_engine.check_ollama_connection()[0]:
        st.error("‚ùå Cannot start interview: AI system is offline. Please ensure Ollama is running.")
        return

    st.session_state.selected_candidate = candidate
    st.session_state.interview_active = True

    # Generate AI opening with real Ollama
    with st.spinner("ü§ñ AI is preparing the interview..."):
        opening = st.session_state.ai_engine.start_interview(candidate, st.session_state.job_requirements)
        st.session_state.conversation_history = st.session_state.ai_engine.conversation_history

    st.success(f"‚úÖ AI Interview started with {candidate['name']}!")
    st.rerun()

def show_candidate_profile(candidate):
    """Show detailed candidate profile"""
    with st.expander(f"üë§ {candidate['name']} - Detailed Profile", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Contact Information:**")
            st.write(f"Email: {candidate.get('email', 'N/A')}")
            st.write(f"Phone: {candidate.get('phone', 'N/A')}")
            st.write(f"Location: {candidate.get('location', 'N/A')}")

            st.write("**Experience:**")
            st.write(f"Years: {candidate.get('experience_years', 0)}")
            st.write(f"Previous Companies: {', '.join(candidate.get('previous_companies', []))}")

        with col2:
            st.write("**Skills:**")
            for skill in candidate.get('skills', []):
                st.write(f"‚Ä¢ {skill}")

            st.write("**Education:**")
            for edu in candidate.get('education', []):
                st.write(f"‚Ä¢ {edu}")

            st.write(f"**Salary Expectation:** {candidate.get('salary_expectation', 'N/A')}")

def show_working_interview():
    """Working AI interview interface"""
    st.header("üé§ AI Interview System")

    if not st.session_state.interview_active:
        st.info("No active interview. Please select a candidate from the Dashboard to start an AI-powered interview.")
        return

    candidate = st.session_state.selected_candidate
    if not candidate:
        st.error("No candidate selected.")
        return

    # Interview header
    st.success(f"üé§ **AI Interview Active:** {candidate['name']} (Match Score: {candidate['match_score']:.1f}%)")

    # AI connection status
    is_connected, _ = st.session_state.ai_engine.check_ollama_connection()
    if is_connected:
        st.info("ü§ñ **AI Status:** Connected to Ollama - Real AI responses active")
    else:
        st.error("‚ùå **AI Status:** Disconnected - Please restart Ollama")

    # Conversation display
    st.subheader("üí¨ AI-Powered Conversation")

    if st.session_state.conversation_history:
        for entry in st.session_state.conversation_history:
            if entry['role'] == 'ai':
                st.markdown(f"""
                <div class="conversation-bubble ai-bubble">
                    <strong>ü§ñ AI Interviewer:</strong><br>
                    {entry['message']}
                    <br><small style="opacity: 0.7;">Generated by AI ‚Ä¢ {datetime.fromisoformat(entry['timestamp']).strftime('%H:%M:%S')}</small>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="conversation-bubble user-bubble">
                    <strong>üë§ {candidate['name']}:</strong><br>
                    {entry['message']}
                    <br><small style="opacity: 0.7;">{datetime.fromisoformat(entry['timestamp']).strftime('%H:%M:%S')}</small>
                </div>
                """, unsafe_allow_html=True)
    else:
        st.info("AI conversation will appear here...")

    # Input interface
    st.subheader("üí¨ Your Response")
    user_input = st.text_area("Type your response:", height=100, key="interview_input")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üì§ Send to AI", type="primary"):
            if user_input.strip():
                send_to_ai(user_input, candidate)
            else:
                st.warning("Please enter a response")

    with col2:
        if st.button("üìù Add Note"):
            st.info("üìù Note added to candidate profile")

    with col3:
        if st.button("‚èπÔ∏è End Interview"):
            end_working_interview(candidate)

def send_to_ai(user_input, candidate):
    """Send user input to AI and get real response"""
    if not st.session_state.ai_engine.check_ollama_connection()[0]:
        st.error("‚ùå Cannot send to AI: Connection lost")
        return

    # Add user message
    st.session_state.conversation_history.append({
        'role': 'user',
        'message': user_input,
        'timestamp': datetime.now().isoformat()
    })

    # Update AI engine conversation history
    st.session_state.ai_engine.conversation_history = st.session_state.conversation_history

    # Generate real AI response
    with st.spinner("ü§ñ AI is thinking..."):
        ai_response = st.session_state.ai_engine.generate_ai_response(
            user_input,
            candidate,
            st.session_state.job_requirements
        )

    # Add AI response
    st.session_state.conversation_history.append({
        'role': 'ai',
        'message': ai_response,
        'timestamp': datetime.now().isoformat()
    })

    # Update AI engine conversation history
    st.session_state.ai_engine.conversation_history = st.session_state.conversation_history

    st.rerun()

def end_working_interview(candidate):
    """End the working interview"""
    # Update candidate status
    for c in st.session_state.candidates:
        if c['id'] == candidate['id']:
            c['status'] = 'Completed'
            break

    # Save interview summary
    interview_summary = {
        'candidate_id': candidate['id'],
        'candidate_name': candidate['name'],
        'total_exchanges': len([msg for msg in st.session_state.conversation_history if msg['role'] == 'user']),
        'duration_minutes': len(st.session_state.conversation_history) * 1.5,
        'end_time': datetime.now().isoformat(),
        'ai_powered': True
    }

    st.session_state.interview_active = False
    st.session_state.selected_candidate = None
    st.session_state.conversation_history = []

    st.success(f"‚úÖ AI Interview completed with {candidate['name']}! Summary saved.")
    st.balloons()
    st.rerun()

def show_working_settings():
    """Working settings interface"""
    st.header("‚öôÔ∏è System Settings")

    # AI Configuration
    st.subheader("ü§ñ AI Configuration")

    is_connected, models_or_error = st.session_state.ai_engine.check_ollama_connection()

    if is_connected:
        st.success(f"‚úÖ Connected to Ollama")
        st.write(f"**Available Models:** {len(models_or_error)}")
        for model in models_or_error:
            st.write(f"‚Ä¢ {model}")
    else:
        st.error(f"‚ùå Connection failed: {models_or_error}")
        st.write("**To fix:** Run `ollama serve` in terminal")

    # Job Configuration
    st.subheader("üíº Job Configuration")

    with st.form("job_config_form"):
        col1, col2 = st.columns(2)

        with col1:
            role = st.text_input("Job Role", value=st.session_state.job_requirements.get('role', ''))
            department = st.text_input("Department", value=st.session_state.job_requirements.get('department', ''))
            required_skills = st.text_area("Required Skills", value=', '.join(st.session_state.job_requirements.get('required_skills', [])))

        with col2:
            min_exp = st.number_input("Min Experience", value=st.session_state.job_requirements.get('min_experience', 0))
            salary_range = st.text_input("Salary Range", value=st.session_state.job_requirements.get('salary_range', ''))

        if st.form_submit_button("üíæ Save Configuration", type="primary"):
            st.session_state.job_requirements = {
                'role': role,
                'department': department,
                'required_skills': [s.strip() for s in required_skills.split(',') if s.strip()],
                'min_experience': min_exp,
                'salary_range': salary_range
            }
            st.success("‚úÖ Job configuration saved!")

if __name__ == "__main__":
    main()
